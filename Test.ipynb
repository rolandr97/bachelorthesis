{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports, Variables & Function definitions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "\r\n",
    "#Imports\r\n",
    "import tensorflow as tf\r\n",
    "from keras.datasets import mnist\r\n",
    "import foolbox as fb\r\n",
    "from keras import callbacks\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\r\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from keras.datasets import mnist\r\n",
    "from sklearn.neighbors import NearestNeighbors\r\n",
    "from itertools import product\r\n",
    "from scipy.ndimage.interpolation import rotate, shift\r\n",
    "import csv\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#Variables\r\n",
    "epsilon=0.3\r\n",
    "batch_size=1024\r\n",
    "epochs=1000\r\n",
    "pgd_steps=50\r\n",
    "batch_count=0\r\n",
    "print(\"Tensorflow version: \", tf.__version__)\r\n",
    "print(\"Numpy version: \", np.__version__)\r\n",
    "print(\"Foolbox version: \", fb.__version__)\r\n",
    "print(tf.config.list_physical_devices('GPU'))\r\n",
    "np.random.seed(10)\r\n",
    "\r\n",
    "\r\n",
    "#get MNIST data and prepare\r\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
    "img_rows = img_cols = 28\r\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
    "x_train = x_train.astype('float32')\r\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\r\n",
    "\r\n",
    "#define variables needed for attacks\r\n",
    "x_attack_to_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\r\n",
    "x_attack_to_train=x_attack_to_train[:,:,:,np.newaxis]\r\n",
    "y_attack_to_train=tf.convert_to_tensor(y_train, dtype=tf.int32)\r\n",
    "\r\n",
    "x_attack_to_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\r\n",
    "x_attack_to_test=x_attack_to_test[:,:,:,np.newaxis]\r\n",
    "y_attack_to_test=tf.convert_to_tensor(y_test, dtype=tf.int32)\r\n",
    "\r\n",
    "attack = fb.attacks.projected_gradient_descent.LinfProjectedGradientDescentAttack(steps=pgd_steps)\r\n",
    "\r\n",
    "#for generating invariance-based adversarial examples\r\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#Functions\r\n",
    "def test_model(model):\r\n",
    "    \r\n",
    "    assert epsilon==0.3\r\n",
    "    inv_advs_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03.npy\")[0:100]\r\n",
    "    inv_labels_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03_labels.npy\")[0:100]\r\n",
    "    fmodel=fb.models.tensorflow.TensorFlowModel(model, bounds=(0,1))      \r\n",
    "    \r\n",
    "\r\n",
    "    # x_batch,y_batch=next_batch(100,x_test,y_test)\r\n",
    "    x_batch,y_batch=x_test[0:100],y_test[0:100]\r\n",
    "    x_batch_to_test = tf.convert_to_tensor(x_batch, dtype=tf.float32)\r\n",
    "    y_batch_to_test=tf.convert_to_tensor(y_batch, dtype=tf.int32)\r\n",
    "\r\n",
    "    _,advs_to_test, success=attack(fmodel,x_batch_to_test, y_batch_to_test, epsilons=epsilon)\r\n",
    "   \r\n",
    "    \r\n",
    "    success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\r\n",
    "    x=tf.keras.backend.get_value(advs_to_test)\r\n",
    "    ptb_test=x\r\n",
    "\r\n",
    "    #get accuracies and losses\r\n",
    "    acc =model.evaluate(x_test[0:100],to_categorical(y_test[0:100]), verbose=0)\r\n",
    "    acc_ptb = model.evaluate(ptb_test,to_categorical(y_batch), verbose=0)\r\n",
    "    acc_inv = model.evaluate(inv_advs_to_test,to_categorical(inv_labels_to_test), verbose=0)\r\n",
    "\r\n",
    "\r\n",
    "    # get invariance adversarial examples success rate\r\n",
    "    predictions=model.predict(inv_advs_to_test)\r\n",
    "    disagreeing=0\r\n",
    "    for i in range(len(predictions)):\r\n",
    "        if inv_labels_to_test[i] !=np.argmax(predictions[i]):\r\n",
    "            disagreeing+=1\r\n",
    "    # plt.imshow(ptb_test[0], cmap='gray')\r\n",
    "    # plt.show()  \r\n",
    "   \r\n",
    "      \r\n",
    "    return {\r\n",
    "    \"clean\":{\"loss\": acc[0], \"accuracy\":acc[1]},\r\n",
    "    \"ptb\":{\"loss\": acc_ptb[0], \"accuracy\":acc_ptb[1]},\r\n",
    "    \"inv\":{\"loss\": acc_inv[0], \"accuracy\":acc_inv[1]},\r\n",
    "    \"inv_success_rate\":disagreeing/100}\r\n",
    "\r\n",
    "\r\n",
    "def create_vanilla_model():\r\n",
    "      print(\"creating vanilla model...\")\r\n",
    "      \r\n",
    "      val_images = x_train[:10000]\r\n",
    "      partial_images = x_train[10000:]\r\n",
    "      val_labels = y_train[:10000]\r\n",
    "      partial_labels = y_train[10000:]\r\n",
    "\r\n",
    "      model = Sequential()\r\n",
    "\r\n",
    "      model.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\r\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "      model.add(Conv2D(64, (5, 5), activation='relu', kernel_initializer='he_uniform'))\r\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "      model.add(Flatten())\r\n",
    "      model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\r\n",
    "      model.add(Dense(10, activation='softmax'))\r\n",
    "     \r\n",
    "\r\n",
    "\r\n",
    "      earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \r\n",
    "                                        mode =\"min\", patience = 1, \r\n",
    "                                        restore_best_weights = True)\r\n",
    "\r\n",
    "      model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
    "      print(\"training vanilla model...\")\r\n",
    "      history=model.fit(partial_images,to_categorical(partial_labels),\r\n",
    "                  validation_data =(val_images, to_categorical(val_labels)),\r\n",
    "                  batch_size=batch_size,\r\n",
    "                  epochs=epochs,\r\n",
    "                  shuffle=True,\r\n",
    "                  verbose=2,\r\n",
    "                  callbacks =[earlystopping]\r\n",
    "                  )\r\n",
    "      print(np.shape(x_test))\r\n",
    "      acc = model.evaluate(x_test[0:100],to_categorical(y_test[0:100]))\r\n",
    "      print('BEFORE RETRAIN: Accuracy on clean testing data', acc[1])\r\n",
    "\r\n",
    "      return model\r\n",
    "\r\n",
    "def create_vanilla_model_tramer(filters=64, s1=5, s2=5, s3=3,\r\n",
    "               d1=0, d2=0, fc=256,\r\n",
    "               lr=1e-3, decay=1e-3):\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Conv2D(filters, kernel_size=(s1, s1),\r\n",
    "                     activation='relu',\r\n",
    "                     input_shape=(28, 28, 1)))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Conv2D(filters*2, (s2, s2), activation='relu'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Conv2D(filters*2, (s3, s3), activation='relu'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Dropout(d1))\r\n",
    "    model.add(Flatten())\r\n",
    "    model.add(Dense(fc, activation='relu'))\r\n",
    "    model.add(Dropout(d2))\r\n",
    "    model.add(Dense(10))\r\n",
    "    \r\n",
    "   \r\n",
    "\r\n",
    "    model.compile(loss='categorical_crossentropy',\r\n",
    "                  optimizer='Adam',\r\n",
    "                  metrics=['accuracy'])\r\n",
    "\r\n",
    "    final = Sequential()\r\n",
    "    final.add(model)\r\n",
    "    final.add(Activation('softmax'))\r\n",
    "    final.compile(loss='categorical_crossentropy',\r\n",
    "                  optimizer='Adam',\r\n",
    "                  metrics=['accuracy'])\r\n",
    "        \r\n",
    "    final.fit(x_train, to_categorical(y_train, 10),\r\n",
    "              batch_size=256,\r\n",
    "              epochs=20,\r\n",
    "              shuffle=True,\r\n",
    "              verbose=2,\r\n",
    "    )\r\n",
    "    return final    \r\n",
    "\r\n",
    "\r\n",
    "# https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data\r\n",
    "# Get random batch of data\r\n",
    "\r\n",
    "\r\n",
    "def next_batch(num, data, labels):\r\n",
    "    global batch_count\r\n",
    "    start=batch_count*num\r\n",
    "    end=(batch_count+1)*num\r\n",
    "\r\n",
    "    print(\"Start: {}, End: {}\".format(start, end))\r\n",
    "    if batch_count<99:\r\n",
    "        batch_count+=1\r\n",
    "    else:\r\n",
    "        batch_count=0\r\n",
    "    \r\n",
    "    return data[start:end], labels[start:end]\r\n",
    "\r\n",
    "\r\n",
    "# def next_batch(num, data, labels):\r\n",
    "#     idx = np.arange(0 , len(data))\r\n",
    "#     np.random.shuffle(idx)\r\n",
    "#     idx = idx[:num]\r\n",
    "#     data_shuffle = [data[ i] for i in idx]\r\n",
    "#     labels_shuffle = [labels[ i] for i in idx]\r\n",
    "#     return np.asarray(data_shuffle), np.asarray(labels_shuffle)\r\n",
    "\r\n",
    "\r\n",
    "# https://github.com/ftramer/Excessive-Invariance\r\n",
    "def linf_attack(x, nn_adv, eps):\r\n",
    "    x_adv = x.copy().astype(np.float32)\r\n",
    "    nn_adv = nn_adv.astype(np.float32)\r\n",
    "    \r\n",
    "    # if possible, change the pixels to the target value\r\n",
    "    idx = np.where((np.abs(nn_adv - x) <= eps*255.) & (x > 0))\r\n",
    "    x_adv[idx] = nn_adv[idx]\r\n",
    "    \r\n",
    "    # otherwise, go as close as possible\r\n",
    "    idx = np.where(np.abs(nn_adv - x) > eps*255.)\r\n",
    "    sign = np.sign(nn_adv - x)\r\n",
    "    x_adv[idx] += sign[idx] * eps * 255.\r\n",
    "    \r\n",
    "    x_adv = np.clip(x_adv, x.astype(np.float32) - eps*255, x.astype(np.float32) + eps*255)\r\n",
    "    x_adv = np.clip(x_adv, 0, 255.)\r\n",
    "    \r\n",
    "    return x_adv\r\n",
    "\r\n",
    "\r\n",
    "# https://github.com/ftramer/Excessive-Invariance\r\n",
    "# tries all rotation-translations of the input and returns the closest neighbor from each class\r\n",
    "def get_best_neighbors(x, y, all_NNs, grid):\r\n",
    "    xs = [shift(rotate(x, r, reshape=False), (tx, ty)).reshape(784) for (tx, ty, r) in grid]\r\n",
    "    xs = np.asarray(xs.copy())\r\n",
    "    \r\n",
    "    nns = []\r\n",
    "    y_nns = []\r\n",
    "    grids_nn = []\r\n",
    "    \r\n",
    "    # find a nearest neighbor in each class\r\n",
    "    for i in range(10):\r\n",
    "        if i != y:\r\n",
    "            X = X_train[Y_train == i]\r\n",
    "            Y = Y_train[Y_train == i]\r\n",
    "            distances, indices = all_NNs[i].kneighbors(xs, n_neighbors=1)\r\n",
    "\r\n",
    "            best = np.argmin(np.reshape(distances, -1))\r\n",
    "            best_idx = np.reshape(indices, -1)[best]\r\n",
    "            nns.append(X[best_idx])\r\n",
    "            y_nns.append(Y[best_idx])\r\n",
    "            \r\n",
    "            # store the inverse rotation+translation to be applied to the target\r\n",
    "            grids_nn.append(-np.asarray(grid[best]))\r\n",
    "    \r\n",
    "    return nns, y_nns, grids_nn\r\n",
    "\r\n",
    "\r\n",
    "# https://github.com/ftramer/Excessive-Invariance\r\n",
    "def generate_inv_adv_examples(epsilon_to_use, count):\r\n",
    "    import numpy as np\r\n",
    "    assert epsilon_to_use==0.3 or epsilon_to_use==0.4\r\n",
    "    \r\n",
    "    idxs=np.arange(0,count,1,dtype=int)\r\n",
    "\r\n",
    "    #  Load the MNIST data. 300 randomly chosen test point\r\n",
    "    assert len(idxs) == count\r\n",
    "    test_xs = X_test[idxs]\r\n",
    "    test_ys = Y_test[idxs]\r\n",
    "\r\n",
    "    # build a nearest neighbors classifier per class\r\n",
    "    N = 1\r\n",
    "    all_NNs = []\r\n",
    "\r\n",
    "    for i in range(10):\r\n",
    "        #Reshape to 1D (28*28=784)\r\n",
    "        X = X_train[Y_train == i].reshape(-1, 784)\r\n",
    "        nn = NearestNeighbors(n_neighbors=N)\r\n",
    "    \r\n",
    "        nn.fit(X)\r\n",
    "        all_NNs.append(nn)\r\n",
    "    # print(all_NNs)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # Rotation-translation parameters\r\n",
    "    limits = [3, 3, 30]\r\n",
    "    granularity = [5, 5, 31]\r\n",
    "    grid = list(product(*list(np.linspace(-l, l, num=g) for l, g in zip(limits, granularity))))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    all_nns = []\r\n",
    "    all_y_nns = []\r\n",
    "    all_grids_nns = []\r\n",
    "\r\n",
    "    # find nearest neighbors for some test inputs (this takes a little while)\r\n",
    "    for i in range(len(idxs)):\r\n",
    "        if i % 10 == 0:\r\n",
    "            print(\"{}/{} done\".format(i, len(idxs)))\r\n",
    "        x = test_xs[i]\r\n",
    "        y = test_ys[i]\r\n",
    "\r\n",
    "        # find the nearest neighbors for each class, with the corresponding rotation and translation\r\n",
    "        nns, y_nns, grids_nns = get_best_neighbors(x, y, all_NNs, grid)\r\n",
    "        nn_advs = [shift(rotate(nn, r, reshape=False), (tx, ty)) for (nn, (tx, ty, r)) in zip(nns, grids_nns)]\r\n",
    "        all_nns.append(nn_advs)\r\n",
    "        all_y_nns.append(y_nns)\r\n",
    "        all_grids_nns.append(np.asarray(grids_nns))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # save everything!\r\n",
    "    np.save(\"data/invariance_examples_generation/X_test_{}.npy\".format(count), test_xs)\r\n",
    "    np.save(\"data/invariance_examples_generation/all_nns.npy\", np.asarray(all_nns))\r\n",
    "    np.save(\"data/invariance_examples_generation/all_y_nns.npy\", np.asarray(all_y_nns))\r\n",
    "    np.save(\"data/invariance_examples_generation/all_grids_nns.npy\", np.asarray(all_grids_nns))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\r\n",
    "    all_nns=np.load(\"data/invariance_examples_generation/all_nns.npy\")\r\n",
    "    all_y_nns=np.load(\"data/invariance_examples_generation/all_y_nns.npy\")\r\n",
    "    all_grids_nns=np.load(\"data/invariance_examples_generation/all_grids_nns.npy\")\r\n",
    "    test_xs=np.load(\"data/invariance_examples_generation/X_test_{}.npy\".format(count))\r\n",
    "  \r\n",
    "    test_ys = y_test[idxs]\r\n",
    "\r\n",
    "    # manually chosen target classes for each source class\r\n",
    "    targets = {\r\n",
    "        0: [4, 6, 8, 9],\r\n",
    "        1: [4, 6, 7, 9],\r\n",
    "        2: [8],\r\n",
    "        3: [8],\r\n",
    "        4: [8, 9],\r\n",
    "        5: [3, 8],\r\n",
    "        6: [0],\r\n",
    "        7: [2, 3],\r\n",
    "        8: [3],\r\n",
    "        9: [3, 4, 5]\r\n",
    "    }\r\n",
    "\r\n",
    "    best_y_advs = []\r\n",
    "    best_targets = []\r\n",
    "    best_advs = []\r\n",
    "\r\n",
    "    for i in range(len(all_nns)):\r\n",
    "        x = test_xs[i]\r\n",
    "        y = test_ys[i]\r\n",
    "    \r\n",
    "        best_x_adv = None\r\n",
    "        best_nn_adv = None\r\n",
    "        amount_removed = []\r\n",
    "        amount_added = []\r\n",
    "        rot = []\r\n",
    "        best_y = None\r\n",
    "        min_removed = np.inf\r\n",
    "        for j in range(len(all_nns[i])):\r\n",
    "            nn_adv = all_nns[i][j]\r\n",
    "            y_nn = all_y_nns[i][j]\r\n",
    "            # print(\"NN ADV: {}\".format(np.shape(nn_adv)))\r\n",
    "            # print(\"X: {}\".format(np.shape(x)))\r\n",
    "            x_adv = linf_attack(x, nn_adv, epsilon_to_use)\r\n",
    "        \r\n",
    "            \r\n",
    "            # retain the target that required the least amount of pixels to be \"removed\"\r\n",
    "            curr_rot = np.abs(all_grids_nns[i][j][-1])\r\n",
    "            curr_removed = np.sum(np.abs(np.maximum(x/255. - x_adv/255., 0)))\r\n",
    "            \r\n",
    "            if y_nn in targets[y] and curr_removed < min_removed:\r\n",
    "                min_removed = curr_removed\r\n",
    "                best_y = y_nn\r\n",
    "                best_x_adv = x_adv\r\n",
    "                best_nn_adv = (nn_adv, y_nn)\r\n",
    "                    \r\n",
    "        best_targets.append(best_nn_adv)\r\n",
    "        best_advs.append(best_x_adv)\r\n",
    "        best_y_advs.append(best_y)\r\n",
    "        \r\n",
    "\r\n",
    "    \r\n",
    "    # if epsilon_to_use==0.3:\r\n",
    "    #     np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples\", best_advs)\r\n",
    "    #     np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels\", best_y_advs)\r\n",
    "    # else:\r\n",
    "    #     np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples\", best_advs)\r\n",
    "    #     np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels\", best_y_advs)\r\n",
    "    \r\n",
    "def ptb_training(ptb_acc_to_achieve, model_to_train, include_inv_training=False, use_iterations=False, iterations=10):\r\n",
    "\r\n",
    "    inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "    inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\r\n",
    "    \r\n",
    "    earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \r\n",
    "                                        mode =\"min\", patience = 1, \r\n",
    "                                       restore_best_weights = True)\r\n",
    "    #While ACCURACY\r\n",
    "    ptb_acc=0\r\n",
    "    i=0\r\n",
    "    y_axis=[]\r\n",
    "    x_axis_ptb=[]\r\n",
    "    x_axis_clean=[]\r\n",
    "    x_axis_inv=[]\r\n",
    "    if use_iterations==False:    \r\n",
    "        while ptb_acc<=ptb_acc_to_achieve:\r\n",
    "            res=test_model(model_to_train)\r\n",
    "            ptb_acc=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "            clean_acc=res.get(\"clean\").get(\"accuracy\")\r\n",
    "            inv_acc=res.get(\"inv\").get(\"accuracy\")\r\n",
    "\r\n",
    "            i+=1\r\n",
    "            y_axis.append(i)\r\n",
    "            x_axis_ptb.append(ptb_acc)\r\n",
    "            x_axis_clean.append(clean_acc)\r\n",
    "            x_axis_inv.append(inv_acc)\r\n",
    "            fmodel=fb.models.tensorflow.TensorFlowModel(model_to_train, bounds=(0,1))   \r\n",
    "            x_batch,y_batch=next_batch(100,x_train,y_train)\r\n",
    "            \r\n",
    "            x_batch_to_train = tf.convert_to_tensor(x_batch, dtype=tf.float32)\r\n",
    "            y_batch_to_train=tf.convert_to_tensor(y_batch, dtype=tf.int32)\r\n",
    "\r\n",
    "            #attack model    \r\n",
    "            _,advs, success=attack(fmodel, x_batch_to_train, y_batch_to_train, epsilons=epsilon) \r\n",
    "            success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\r\n",
    "            \r\n",
    "            #Retrain model with generated perturbation-based adversarial examples\r\n",
    "            #80% Training 20% Validation\r\n",
    "            x=tf.keras.backend.get_value(advs)\r\n",
    "            # print(\"Shape of x_training before reshape: {}\".format(np.shape(x)))\r\n",
    "            # print(\"Shape of x_training after reshape: {}\".format(np.shape(x)))\r\n",
    "            x_training=x[0:int(len(x)*0.8)]\r\n",
    "            x_validation=x[int(len(x)*0.8):int(len(x))]\r\n",
    "            y_training=y_batch[0:int(len(x)*0.8)]\r\n",
    "            y_validation=y_batch[int(len(x)*0.8):int(len(x))]\r\n",
    "            \r\n",
    "            model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\r\n",
    "                validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\r\n",
    "                epochs=epochs,\r\n",
    "                verbose=0,\r\n",
    "                callbacks =[earlystopping]\r\n",
    "            )\r\n",
    "\r\n",
    "\r\n",
    "            if include_inv_training==True:\r\n",
    "                model_to_train.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\r\n",
    "                    epochs=10,\r\n",
    "                    verbose=0\r\n",
    "                )\r\n",
    "        \r\n",
    "\r\n",
    "            print(\"i: {} ptb acc: {}, inv_acc: {}\".format(i,ptb_acc, inv_acc))\r\n",
    "    else:\r\n",
    "        while i<iterations:\r\n",
    "            res=test_model(model_to_train)\r\n",
    "            ptb_acc=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "            clean_acc=res.get(\"clean\").get(\"accuracy\")\r\n",
    "            inv_acc=res.get(\"inv\").get(\"accuracy\")\r\n",
    "\r\n",
    "            i+=1\r\n",
    "            y_axis.append(i)\r\n",
    "            x_axis_ptb.append(ptb_acc)\r\n",
    "            x_axis_clean.append(clean_acc)\r\n",
    "            x_axis_inv.append(inv_acc)\r\n",
    "            fmodel=fb.models.tensorflow.TensorFlowModel(model_to_train, bounds=(0,1))   \r\n",
    "            x_batch,y_batch=next_batch(100,x_train,y_train)\r\n",
    "            \r\n",
    "            x_batch_to_train = tf.convert_to_tensor(x_batch, dtype=tf.float32)\r\n",
    "            y_batch_to_train=tf.convert_to_tensor(y_batch, dtype=tf.int32)\r\n",
    "\r\n",
    "            #attack model    \r\n",
    "            _,advs, success=attack(fmodel, x_batch_to_train, y_batch_to_train, epsilons=epsilon) \r\n",
    "            success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\r\n",
    "            \r\n",
    "            #Retrain model with generated perturbation-based adversarial examples\r\n",
    "            #80% Training 20% Validation\r\n",
    "            x=tf.keras.backend.get_value(advs)\r\n",
    "            # print(\"Shape of x_training before reshape: {}\".format(np.shape(x)))\r\n",
    "            # print(\"Shape of x_training after reshape: {}\".format(np.shape(x)))\r\n",
    "            x_training=x[0:int(len(x)*0.8)]\r\n",
    "            x_validation=x[int(len(x)*0.8):int(len(x))]\r\n",
    "            y_training=y_batch[0:int(len(x)*0.8)]\r\n",
    "            y_validation=y_batch[int(len(x)*0.8):int(len(x))]\r\n",
    "            \r\n",
    "            model_to_train.fit(x_training,to_categorical(y_training,num_classes=10),\r\n",
    "                validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\r\n",
    "                epochs=epochs,\r\n",
    "                verbose=0,\r\n",
    "                callbacks =[earlystopping]\r\n",
    "            )\r\n",
    "\r\n",
    "\r\n",
    "            if include_inv_training==True:\r\n",
    "                model_to_train.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\r\n",
    "                    epochs=10,\r\n",
    "                    verbose=0\r\n",
    "                )\r\n",
    "        \r\n",
    "\r\n",
    "            print(\"i: {} ptb acc: {}, inv_acc: {}\".format(i,ptb_acc, inv_acc))\r\n",
    "    plt.plot( y_axis, x_axis_inv, label = \"INV\")\r\n",
    "    plt.plot( y_axis, x_axis_clean, label = \"Clean\")\r\n",
    "    plt.plot( y_axis, x_axis_ptb,label = \"PTB\")\r\n",
    "    plt.xlabel('Iterationen')\r\n",
    "    plt.ylabel('Accuracy')\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "    return {\r\n",
    "        \"model\": model_to_train,\r\n",
    "        \"clean\":{ \"accuracy\": x_axis_clean},\r\n",
    "        \"ptb\":{\"accuracy\":x_axis_ptb},\r\n",
    "        \"inv\":{\"accuracy\":x_axis_inv},\r\n",
    "        \r\n",
    "\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create/train vanilla model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "create_vanilla_model().save(\"models/vanilla_model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attack Vanilla Model and Retrain with Perturbation-Based Adversarial Examples iteratively\n",
    "Result is ptb_trained_model\n",
    "\n",
    "Takes a few minutes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get Model\r\n",
    "model=load_model(\"models/vanilla_model\")\r\n",
    "\r\n",
    "ptb_acc_to_achieve=0.88\r\n",
    "model,ptb_acc=ptb_training(ptb_acc_to_achieve, model)\r\n",
    "model.save(\"models/ptb_trained_model_{}_ptb_accuracy\".format(ptb_acc)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot PTB Adversarial Training graphs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def filter_array(array):\r\n",
    "    filtered=[]\r\n",
    "    for i in range(len(array)):\r\n",
    "        if i%10==0:\r\n",
    "            filtered.append(array[i])\r\n",
    "    return filtered\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "y=np.load(\"data/ptb_training/iteration_count_arr.npy\")\r\n",
    "clean_arr=np.load(\"data/ptb_training/clean_accuracy_arr.npy\")\r\n",
    "ptb_arr=np.load(\"data/ptb_training/ptb_accuracy_arr.npy\")\r\n",
    "plt.plot( y, clean_arr, label = \"Clean\")\r\n",
    "plt.plot( y, ptb_arr,label = \"PTB\")\r\n",
    "plt.xlabel('Iterationen')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "new_arr_x_ptb=filter_array(ptb_arr)\r\n",
    "new_arr_x_clean=filter_array(clean_arr)\r\n",
    "new_arr_y=filter_array(y)\r\n",
    "\r\n",
    "\r\n",
    "plt.plot( new_arr_y, new_arr_x_clean, label = \"Clean\")\r\n",
    "plt.plot( new_arr_y, new_arr_x_ptb,label = \"PTB\")\r\n",
    "plt.xlabel('Iterationen')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"Max accuracy against PTB: {}\".format(np.max(ptb_arr)))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate INV-Based ADV-Examples \n",
    "Code is from https://github.com/ftramer/Excessive-Invariance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# generate_inv_adv_examples(0.3,500)\r\n",
    "# generate_inv_adv_examples(0.4,500)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot INV-Based ADV-Examples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\r\n",
    "\r\n",
    "print(\"----------EPSILON=0.3----------\")\r\n",
    "fig, axes = plt.subplots(50,10, figsize=(1.5*10,2*50))\r\n",
    "for i in range(500):\r\n",
    "    ax = axes[i//10,i%10]\r\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\r\n",
    "    # ax.set_title('Label: {}'.format(inv_labels_to_train[i]))\r\n",
    "    ax.set_title('Count: {}'.format(i))\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples.npy\")\r\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels.npy\")\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "print()\r\n",
    "print(\"----------EPSILON=0.4----------\")\r\n",
    "fig, axes = plt.subplots(50,10, figsize=(1.5*10,2*50))\r\n",
    "for i in range(500):\r\n",
    "    ax = axes[i//10,i%10]\r\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\r\n",
    "    # ax.set_title('Label: {}'.format(inv_labels_to_train[i]))\r\n",
    "    ax.set_title('Count: {}'.format(i))\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Erster Durchlauf (Anzahl an Invariance-Based Adversarial Examples beim Trainieren variiert. Immer die neuen Labels verÃ¤ndern)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# epsilon\r\n",
    "epsilon=0.3\r\n",
    "\r\n",
    "# c\r\n",
    "\r\n",
    "c=[]\r\n",
    "i=500\r\n",
    "j=5\r\n",
    "while j<=i:\r\n",
    "    c.append(j)\r\n",
    "    j+=5\r\n",
    "\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "\r\n",
    "# m=l_infinity_PGD\r\n",
    "# a=88.9\r\n",
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\r\n",
    "\r\n",
    "# Invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\r\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Initialize writing results to csv\r\n",
    "handler_inv_trained = open('data/results/erster_durchlauf/inv_trained.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_inv_trained = csv.writer(handler_inv_trained)\r\n",
    "writer_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\r\n",
    "\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/erster_durchlauf/ptb_inv_trained.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\r\n",
    "writer_ptb_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "initial_results_vanilla=test_model(vanilla_model)\r\n",
    "initial_results_ptb=test_model(ptb_trained_model)\r\n",
    "\r\n",
    "data=[0,initial_results_vanilla.get(\"clean\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"inv\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"clean\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"inv\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "writer_inv_trained.writerow(data)\r\n",
    "\r\n",
    "data=[0,initial_results_ptb.get(\"clean\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"inv\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"clean\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"ptb\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"inv\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "writer_ptb_inv_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "print(\"Initial results from Vanilla Model: {}\".format(initial_results_vanilla))\r\n",
    "print(\"Initial results from PTB-Trained Model: {}\".format(initial_results_ptb))\r\n",
    "\r\n",
    "\r\n",
    "results_inv_trained=[]\r\n",
    "results_ptb_inv_trained=[]\r\n",
    "for i in range(len(c)):\r\n",
    "    print(\"Training with {} examples...\".format(c[i]))\r\n",
    "\r\n",
    "    vanilla_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\r\n",
    "    epochs=10,\r\n",
    "    verbose=0)\r\n",
    "    \r\n",
    "\r\n",
    "    res=test_model(vanilla_model)\r\n",
    "    results_inv_trained.append(res)\r\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\r\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    res.get(\"inv\").get(\"accuracy\"),\r\n",
    "    res.get(\"clean\").get(\"loss\"),\r\n",
    "    res.get(\"ptb\").get(\"loss\"),\r\n",
    "    res.get(\"inv\").get(\"loss\"),\r\n",
    "    res.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "    # write to csv file\r\n",
    "    writer_inv_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    ptb_trained_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\r\n",
    "    epochs=10,\r\n",
    "    verbose=0)\r\n",
    "\r\n",
    "    res=test_model(ptb_trained_model)\r\n",
    "    results_ptb_inv_trained.append(res)\r\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\r\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    res.get(\"inv\").get(\"accuracy\"),\r\n",
    "    res.get(\"clean\").get(\"loss\"),\r\n",
    "    res.get(\"ptb\").get(\"loss\"),\r\n",
    "    res.get(\"inv\").get(\"loss\"),\r\n",
    "    res.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "    #write to csv file\r\n",
    "    writer_ptb_inv_trained.writerow(data)\r\n",
    "\r\n",
    "    #reload models...\r\n",
    "    vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "    ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\r\n",
    "handler_ptb_inv_trained.close()\r\n",
    "handler_inv_trained.close()\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "print(\"----------Results INV-Trained Model----------\")\r\n",
    "i=0\r\n",
    "for entry in results_inv_trained:\r\n",
    "    print(\"Clean accuracy INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\r\n",
    "    i+=1\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "print(\"----------Results PTB-INV-Trained Model----------\")\r\n",
    "i=0\r\n",
    "for entry in results_ptb_inv_trained:\r\n",
    "    print(\"Clean accuracy PTB-INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\r\n",
    "    i+=1\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ersten Durchlauf evaluieren"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "handler_inv_trained = open('data/results/erster_durchlauf/inv_trained.csv', 'r')\r\n",
    "reader_inv_trained = csv.DictReader(handler_inv_trained)\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/erster_durchlauf/ptb_inv_trained.csv', 'r')\r\n",
    "reader_ptb_inv_trained = csv.DictReader(handler_ptb_inv_trained)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "inv_trained_clean=[]\r\n",
    "inv_trained_ptb=[]\r\n",
    "inv_trained_inv=[]\r\n",
    "\r\n",
    "ptb_inv_trained_clean=[]\r\n",
    "ptb_inv_trained_ptb=[]\r\n",
    "ptb_inv_trained_inv=[]\r\n",
    "\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_inv_trained:\r\n",
    "    \r\n",
    "    inv_trained_clean.append(float(row[\"clean_acc\"]))        \r\n",
    "    inv_trained_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "    inv_trained_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_ptb_inv_trained:\r\n",
    "    \r\n",
    "    ptb_inv_trained_clean.append(float(row[\"clean_acc\"]))\r\n",
    "    ptb_inv_trained_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "    ptb_inv_trained_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "\r\n",
    "y=[]\r\n",
    "i=500\r\n",
    "j=0\r\n",
    "while j<=500:\r\n",
    "    y.append(j)\r\n",
    "    j+=5\r\n",
    "\r\n",
    "\r\n",
    "print(\"INV-Trained\")  \r\n",
    "plt.plot( y, inv_trained_clean, label = \"Clean\")\r\n",
    "plt.plot( y, inv_trained_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, inv_trained_inv,label = \"INV\")\r\n",
    "plt.xlabel('c')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"PTB-INV-Trained\")\r\n",
    "plt.plot( y, ptb_inv_trained_clean, label = \"Clean\")\r\n",
    "plt.plot( y, ptb_inv_trained_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, ptb_inv_trained_inv,label = \"INV\")\r\n",
    "plt.xlabel('c')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "inv_trained_clean={\r\n",
    "    \"initial\": inv_trained_clean[0],\r\n",
    "    \"mean\":np.mean(inv_trained_clean),\r\n",
    "    \"min\":np.min(inv_trained_clean),\r\n",
    "    \"max\":np.max(inv_trained_clean)\r\n",
    "}\r\n",
    "\r\n",
    "inv_trained_ptb={\r\n",
    "    \"initial\": inv_trained_ptb[0],\r\n",
    "    \"mean\":np.mean(inv_trained_ptb),\r\n",
    "    \"min\":np.min(inv_trained_ptb),\r\n",
    "    \"max\":np.max(inv_trained_ptb)\r\n",
    "}\r\n",
    "\r\n",
    "inv_trained_inv={\r\n",
    "    \"initial\": inv_trained_inv[0],\r\n",
    "    \"mean\":np.mean(inv_trained_inv),\r\n",
    "    \"min\":np.min(inv_trained_inv),\r\n",
    "    \"max\":np.max(inv_trained_inv)\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "ptb_inv_trained_clean={\r\n",
    "    \"initial\": ptb_inv_trained_clean[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_clean),\r\n",
    "    \"min\":np.min(ptb_inv_trained_clean),\r\n",
    "    \"max\":np.max(ptb_inv_trained_clean)\r\n",
    "}\r\n",
    "\r\n",
    "ptb_inv_trained_ptb={\r\n",
    "    \"initial\": ptb_inv_trained_ptb[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_ptb),\r\n",
    "    \"min\":np.min(ptb_inv_trained_ptb),\r\n",
    "    \"max\":np.max(ptb_inv_trained_ptb)\r\n",
    "}\r\n",
    "\r\n",
    "ptb_inv_trained_inv={\r\n",
    "    \"initial\": ptb_inv_trained_inv[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_inv),\r\n",
    "    \"min\":np.min(ptb_inv_trained_inv),\r\n",
    "    \"max\":np.max(ptb_inv_trained_inv)\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"INV_TRAINED\")\r\n",
    "print()\r\n",
    "print(\"INV-TRAINED CLEAN: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_clean.get(\"initial\"),inv_trained_clean.get(\"min\"),inv_trained_clean.get(\"max\"),inv_trained_clean.get(\"mean\")))\r\n",
    "print(\"INV-TRAINED PTB: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_ptb.get(\"initial\"),inv_trained_ptb.get(\"min\"),inv_trained_ptb.get(\"max\"),inv_trained_ptb.get(\"mean\")))\r\n",
    "print(\"INV-TRAINED INV: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_inv.get(\"initial\"),inv_trained_inv.get(\"min\"),inv_trained_inv.get(\"max\"),inv_trained_inv.get(\"mean\")))\r\n",
    "print()\r\n",
    "print()\r\n",
    "print(\"PTB-INV_TRAINED\")\r\n",
    "print()\r\n",
    "print(\"PTB_INV-TRAINED CLEAN: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_clean.get(\"initial\"),ptb_inv_trained_clean.get(\"min\"),ptb_inv_trained_clean.get(\"max\"),ptb_inv_trained_clean.get(\"mean\")))\r\n",
    "print(\"PTB_INV-TRAINED PTB: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_ptb.get(\"initial\"),ptb_inv_trained_ptb.get(\"min\"),ptb_inv_trained_ptb.get(\"max\"),ptb_inv_trained_ptb.get(\"mean\")))\r\n",
    "print(\"PTB_INV-TRAINED INV: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_inv.get(\"initial\"),ptb_inv_trained_inv.get(\"min\"),ptb_inv_trained_inv.get(\"max\"),ptb_inv_trained_inv.get(\"mean\")))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zweiter Durchlauf (Dasselbe wie beim ersten Durchlauf mit dem Unterschied, dass die Labels beim Retrainieren mit Invariance-Based Adversarial Examples von zehn Personen bestimmt wurden)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# epsilon\r\n",
    "epsilon=0.3\r\n",
    "\r\n",
    "# c\r\n",
    "c=[]\r\n",
    "i=500\r\n",
    "j=5\r\n",
    "while j<=i:\r\n",
    "    c.append(j)\r\n",
    "    j+=5\r\n",
    "\r\n",
    "\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "\r\n",
    "# m=l_infinity_PGD\r\n",
    "# a=88.9\r\n",
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\r\n",
    "\r\n",
    "# Invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\r\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\r\n",
    "\r\n",
    "print(np.shape(inv_labels_to_train))\r\n",
    "\r\n",
    "# Initialize writing results to csv\r\n",
    "handler_inv_trained = open('data/results/zweiter_durchlauf/inv_trained.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_inv_trained = csv.writer(handler_inv_trained)\r\n",
    "writer_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\r\n",
    "\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/zweiter_durchlauf/ptb_inv_trained.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\r\n",
    "writer_ptb_inv_trained.writerow([\"c\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", \"clean_loss\", \"ptb_loss\", \"inv_loss\", \"inv_success_rate\" ])\r\n",
    "\r\n",
    "initial_results_vanilla=test_model(vanilla_model)\r\n",
    "initial_results_ptb=test_model(ptb_trained_model)\r\n",
    "\r\n",
    "data=[0,initial_results_vanilla.get(\"clean\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"inv\").get(\"accuracy\"),\r\n",
    "    initial_results_vanilla.get(\"clean\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"ptb\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"inv\").get(\"loss\"),\r\n",
    "    initial_results_vanilla.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "writer_inv_trained.writerow(data)\r\n",
    "\r\n",
    "data=[0,initial_results_ptb.get(\"clean\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"inv\").get(\"accuracy\"),\r\n",
    "    initial_results_ptb.get(\"clean\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"ptb\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"inv\").get(\"loss\"),\r\n",
    "    initial_results_ptb.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "writer_ptb_inv_trained.writerow(data)\r\n",
    "\r\n",
    "print(\"Initial results from Vanilla Model: {}\".format(initial_results_vanilla))\r\n",
    "print(\"Initial results from PTB-Trained Model: {}\".format(initial_results_ptb))\r\n",
    "\r\n",
    "\r\n",
    "results_inv_trained=[]\r\n",
    "results_ptb_inv_trained=[]\r\n",
    "for i in range(len(c)):\r\n",
    "    print(\"Training with {} examples...\".format(c[i]))\r\n",
    "\r\n",
    "    vanilla_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\r\n",
    "    epochs=10,\r\n",
    "    verbose=0)\r\n",
    "    \r\n",
    "\r\n",
    "    res=test_model(vanilla_model)\r\n",
    "    results_inv_trained.append(res)\r\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\r\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    res.get(\"inv\").get(\"accuracy\"),\r\n",
    "    res.get(\"clean\").get(\"loss\"),\r\n",
    "    res.get(\"ptb\").get(\"loss\"),\r\n",
    "    res.get(\"inv\").get(\"loss\"),\r\n",
    "    res.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "    # write to csv file\r\n",
    "    writer_inv_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    ptb_trained_model.fit(inv_advs_to_train[0:c[i]],to_categorical(inv_labels_to_train[0:c[i]],num_classes=10),\r\n",
    "    epochs=10,\r\n",
    "    verbose=0)\r\n",
    "\r\n",
    "    res=test_model(ptb_trained_model)\r\n",
    "    results_ptb_inv_trained.append(res)\r\n",
    "    data=[c[i],res.get(\"clean\").get(\"accuracy\"),\r\n",
    "    res.get(\"ptb\").get(\"accuracy\"),\r\n",
    "    res.get(\"inv\").get(\"accuracy\"),\r\n",
    "    res.get(\"clean\").get(\"loss\"),\r\n",
    "    res.get(\"ptb\").get(\"loss\"),\r\n",
    "    res.get(\"inv\").get(\"loss\"),\r\n",
    "    res.get(\"inv_success_rate\"),\r\n",
    "    ]\r\n",
    "\r\n",
    "    #write to csv file\r\n",
    "    writer_ptb_inv_trained.writerow(data)\r\n",
    "\r\n",
    "    #reload models...\r\n",
    "    vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "    ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy_PGD\")\r\n",
    "\r\n",
    "handler_ptb_inv_trained.close()\r\n",
    "handler_inv_trained.close()\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "print(\"----------Results INV-Trained Model----------\")\r\n",
    "i=0\r\n",
    "for entry in results_inv_trained:\r\n",
    "    print(\"Clean accuracy INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\r\n",
    "    i+=1\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "print(\"----------Results PTB-INV-Trained Model----------\")\r\n",
    "i=0\r\n",
    "for entry in results_ptb_inv_trained:\r\n",
    "    print(\"Clean accuracy PTB-INV_trained with {} examples: {}\".format(c[i],entry.get(\"clean\").get(\"accuracy\")))\r\n",
    "    i+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zweiten Durchlauf evaluieren"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "handler_inv_trained = open('data/results/zweiter_durchlauf/inv_trained.csv', 'r')\r\n",
    "reader_inv_trained = csv.DictReader(handler_inv_trained)\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/zweiter_durchlauf/ptb_inv_trained.csv', 'r')\r\n",
    "reader_ptb_inv_trained = csv.DictReader(handler_ptb_inv_trained)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "inv_trained_clean=[]\r\n",
    "inv_trained_ptb=[]\r\n",
    "inv_trained_inv=[]\r\n",
    "\r\n",
    "ptb_inv_trained_clean=[]\r\n",
    "ptb_inv_trained_ptb=[]\r\n",
    "ptb_inv_trained_inv=[]\r\n",
    "\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_inv_trained:\r\n",
    "    \r\n",
    "    inv_trained_clean.append(float(row[\"clean_acc\"]))        \r\n",
    "    inv_trained_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "    inv_trained_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_ptb_inv_trained:\r\n",
    "    \r\n",
    "    ptb_inv_trained_clean.append(float(row[\"clean_acc\"]))\r\n",
    "    ptb_inv_trained_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "    ptb_inv_trained_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "\r\n",
    "y=[]\r\n",
    "i=500\r\n",
    "j=0\r\n",
    "while j<=500:\r\n",
    "    y.append(j)\r\n",
    "    j+=5\r\n",
    "\r\n",
    "print(\"INV-Trained\")  \r\n",
    "plt.plot( y, inv_trained_clean, label = \"Clean\")\r\n",
    "plt.plot( y, inv_trained_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, inv_trained_inv,label = \"INV\")\r\n",
    "plt.xlabel('c')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "print(\"PTB-INV-Trained\")\r\n",
    "plt.plot( y, ptb_inv_trained_clean, label = \"Clean\")\r\n",
    "plt.plot( y, ptb_inv_trained_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, ptb_inv_trained_inv,label = \"INV\")\r\n",
    "plt.xlabel('c')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "inv_trained_clean={\r\n",
    "    \"initial\": inv_trained_clean[0],\r\n",
    "    \"mean\":np.mean(inv_trained_clean),\r\n",
    "    \"min\":np.min(inv_trained_clean),\r\n",
    "    \"max\":np.max(inv_trained_clean)\r\n",
    "}\r\n",
    "\r\n",
    "inv_trained_ptb={\r\n",
    "    \"initial\": inv_trained_ptb[0],\r\n",
    "    \"mean\":np.mean(inv_trained_ptb),\r\n",
    "    \"min\":np.min(inv_trained_ptb),\r\n",
    "    \"max\":np.max(inv_trained_ptb)\r\n",
    "}\r\n",
    "\r\n",
    "inv_trained_inv={\r\n",
    "    \"initial\": inv_trained_inv[0],\r\n",
    "    \"mean\":np.mean(inv_trained_inv),\r\n",
    "    \"min\":np.min(inv_trained_inv),\r\n",
    "    \"max\":np.max(inv_trained_inv)\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "ptb_inv_trained_clean={\r\n",
    "    \"initial\": ptb_inv_trained_clean[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_clean),\r\n",
    "    \"min\":np.min(ptb_inv_trained_clean),\r\n",
    "    \"max\":np.max(ptb_inv_trained_clean)\r\n",
    "}\r\n",
    "\r\n",
    "ptb_inv_trained_ptb={\r\n",
    "    \"initial\": ptb_inv_trained_ptb[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_ptb),\r\n",
    "    \"min\":np.min(ptb_inv_trained_ptb),\r\n",
    "    \"max\":np.max(ptb_inv_trained_ptb)\r\n",
    "}\r\n",
    "\r\n",
    "ptb_inv_trained_inv={\r\n",
    "    \"initial\": ptb_inv_trained_inv[0],\r\n",
    "    \"mean\":np.mean(ptb_inv_trained_inv),\r\n",
    "    \"min\":np.min(ptb_inv_trained_inv),\r\n",
    "    \"max\":np.max(ptb_inv_trained_inv)\r\n",
    "}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"INV_TRAINED\")\r\n",
    "print()\r\n",
    "print(\"INV-TRAINED CLEAN: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_clean.get(\"initial\"),inv_trained_clean.get(\"min\"),inv_trained_clean.get(\"max\"),inv_trained_clean.get(\"mean\")))\r\n",
    "print(\"INV-TRAINED PTB: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_ptb.get(\"initial\"),inv_trained_ptb.get(\"min\"),inv_trained_ptb.get(\"max\"),inv_trained_ptb.get(\"mean\")))\r\n",
    "print(\"INV-TRAINED INV: initial: {}, min: {}, max: {}, mean: {}\".format(inv_trained_inv.get(\"initial\"),inv_trained_inv.get(\"min\"),inv_trained_inv.get(\"max\"),inv_trained_inv.get(\"mean\")))\r\n",
    "print()\r\n",
    "print()\r\n",
    "print(\"PTB-INV_TRAINED\")\r\n",
    "print()\r\n",
    "print(\"PTB_INV-TRAINED CLEAN: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_clean.get(\"initial\"),ptb_inv_trained_clean.get(\"min\"),ptb_inv_trained_clean.get(\"max\"),ptb_inv_trained_clean.get(\"mean\")))\r\n",
    "print(\"PTB_INV-TRAINED PTB: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_ptb.get(\"initial\"),ptb_inv_trained_ptb.get(\"min\"),ptb_inv_trained_ptb.get(\"max\"),ptb_inv_trained_ptb.get(\"mean\")))\r\n",
    "print(\"PTB_INV-TRAINED INV: initial: {}, min: {}, max: {}, mean: {}\".format(ptb_inv_trained_inv.get(\"initial\"),ptb_inv_trained_inv.get(\"min\"),ptb_inv_trained_inv.get(\"max\"),ptb_inv_trained_inv.get(\"mean\")))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dritter Durchlauf (PTB-INV Trained oder INV-PTB Trained?)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# epsilon\r\n",
    "epsilon=0.3\r\n",
    "iterations=1500\r\n",
    "ptb_acc_to_achieve=1\r\n",
    "\r\n",
    "# Invariance-Based Adversarial Examples to train, use ONLY THE NEW LABELS\r\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#Handler and writer...\r\n",
    "handler_simultan_trained = open('data/results/dritter_durchlauf/simultan.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_simultan_trained = csv.writer(handler_simultan_trained)\r\n",
    "writer_simultan_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\"])\r\n",
    "\r\n",
    "handler_not_simultan_trained = open('data/results/dritter_durchlauf/not_simultan.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_not_simultan_trained = csv.writer(handler_not_simultan_trained)\r\n",
    "writer_not_simultan_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", ])\r\n",
    "\r\n",
    "handler_inv_ptb_trained = open('data/results/dritter_durchlauf/inv_ptb.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_inv_ptb_trained = csv.writer(handler_inv_ptb_trained)\r\n",
    "writer_inv_ptb_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", ])\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/dritter_durchlauf/Sptb_inv.csv', 'w',encoding='UTF8',newline='')\r\n",
    "writer_ptb_inv_trained = csv.writer(handler_ptb_inv_trained)\r\n",
    "writer_ptb_inv_trained.writerow([\"i\",\"clean_acc\",\"ptb_acc\", \"inv_acc\", ])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Simultan training\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "res=ptb_training(ptb_acc_to_achieve=ptb_acc_to_achieve, vanilla_model, include_inv_training=True, use_iterations=True, iterations=iterations)\r\n",
    "\r\n",
    "ptb_acc_arr_simultan=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "inv_acc_arr_simultan=res.get(\"inv\").get(\"accuracy\")\r\n",
    "clean_acc_arr_simultan=res.get(\"clean\").get(\"accuracy\")\r\n",
    "\r\n",
    "\r\n",
    "for i in range(iterations):\r\n",
    "    data=[i,clean_acc_arr_simultan[i],ptb_acc_arr_simultan[i],inv_acc_arr_simultan[i]]\r\n",
    "    writer_simultan_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Not simultan trainin\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "res=ptb_training(ptb_acc_to_achieve=ptb_acc_to_achieve, vanilla_model, include_inv_training=False, use_iterations=True, iterations=iterations)\r\n",
    "\r\n",
    "ptb_acc_arr_not_simultan=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "inv_acc_arr_not_simultan=res.get(\"inv\").get(\"accuracy\")\r\n",
    "clean_acc_arr_not_simultan=res.get(\"clean\").get(\"accuracy\")\r\n",
    "\r\n",
    "for i in range(iterations):\r\n",
    "    data=[i,clean_acc_arr_not_simultan[i],ptb_acc_arr_not_simultan[i],inv_acc_arr_not_simultan[i]]\r\n",
    "    writer_not_simultan_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"INV-PTB\")\r\n",
    "\r\n",
    "\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "\r\n",
    "# first INV-Training...\r\n",
    "print(\"INV-Training\")\r\n",
    "vanilla_model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\r\n",
    "epochs=10,\r\n",
    "verbose=0)\r\n",
    "\r\n",
    "\r\n",
    "# then PTB-Training\r\n",
    "res=ptb_training(ptb_acc_to_achieve=ptb_acc_to_achieve, vanilla_model,use_iterations=True, iterations=iterations)\r\n",
    "\r\n",
    "\r\n",
    "ptb_acc_arr_inv_ptb=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "inv_acc_arr_inv_ptb=res.get(\"inv\").get(\"accuracy\")\r\n",
    "clean_acc_arr_inv_ptb=res.get(\"clean\").get(\"accuracy\")\r\n",
    "\r\n",
    "for i in range(iterations):\r\n",
    "    data=[i,clean_acc_arr_inv_ptb[i],ptb_acc_arr_inv_ptb[i],inv_acc_arr_inv_ptb[i]]\r\n",
    "    writer_inv_ptb_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(\"PTB-INV\")\r\n",
    "\r\n",
    "\r\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\r\n",
    "\r\n",
    "#first PTB-Training\r\n",
    "\r\n",
    "# then PTB-Training\r\n",
    "res=ptb_training(ptb_acc_to_achieve=ptb_acc_to_achieve, vanilla_model,use_iterations=True, iterations=iterations)\r\n",
    "\r\n",
    "\r\n",
    "# then INV-Training\r\n",
    "print(\"INV-Training\")\r\n",
    "model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\r\n",
    "    epochs=10,\r\n",
    "    verbose=0)\r\n",
    "\r\n",
    "\r\n",
    "ptb_acc_arr_ptb_inv=res.get(\"ptb\").get(\"accuracy\")\r\n",
    "inv_acc_arr_ptb_inv=res.get(\"inv\").get(\"accuracy\")\r\n",
    "clean_acc_arr_ptb_inv=res.get(\"clean\").get(\"accuracy\")\r\n",
    "\r\n",
    "for i in range(iterations):\r\n",
    "    data=[i,clean_acc_arr_ptb_inv[i],ptb_acc_arr_ptb_inv[i],inv_acc_arr_ptb_inv[i]]\r\n",
    "    writer_ptb_inv_trained.writerow(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "handler_not_simultan_trained.close()\r\n",
    "handler_ptb_inv_trained.close()\r\n",
    "handler_simultan_trained.close()\r\n",
    "hanler_inv_ptb_trained.close()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dritten Durchlauf evaluieren"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resolution=5\r\n",
    "\r\n",
    "\r\n",
    "handler_simultan_trained = open('data/results/dritter_durchlauf/simultan.csv', 'r')\r\n",
    "reader_simultan_trained = csv.DictReader(handler_simultan_trained)\r\n",
    "\r\n",
    "handler_not_simultan_trained = open('data/results/dritter_durchlauf/not_simultan.csv', 'r')\r\n",
    "reader_not_simultan_trained = csv.DictReader(handler_not_simultan_trained)\r\n",
    "\r\n",
    "handler_inv_ptb_trained = open('data/results/dritter_durchlauf/inv_ptb.csv', 'r')\r\n",
    "reader_inv_ptb_trained = csv.DictReader(handler_inv_ptb_trained)\r\n",
    "\r\n",
    "handler_ptb_inv_trained = open('data/results/dritter_durchlauf/ptb_inv.csv', 'r')\r\n",
    "reader_ptb_inv_trained = csv.DictReader(handler_ptb_inv_trained)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "simultan_clean=[]\r\n",
    "simultan_ptb=[]\r\n",
    "simultan_inv=[]\r\n",
    "\r\n",
    "simultan_clean_all=[]\r\n",
    "simultan_ptb_all=[]\r\n",
    "simultan_inv_all=[]\r\n",
    "\r\n",
    "not_simultan_clean=[]\r\n",
    "not_simultan_ptb=[]\r\n",
    "not_simultan_inv=[]\r\n",
    "\r\n",
    "inv_ptb_clean=[]\r\n",
    "inv_ptb_ptb=[]\r\n",
    "inv_ptb_inv=[]\r\n",
    "\r\n",
    "ptb_inv_clean=[]\r\n",
    "ptb_inv_ptb=[]\r\n",
    "ptb_inv_inv=[]\r\n",
    "\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_simultan_trained: \r\n",
    "    simultan_clean_all.append(float(row[\"clean_acc\"]))        \r\n",
    "    simultan_ptb_all.append(float(row[\"ptb_acc\"]))\r\n",
    "    simultan_inv_all.append(float(row[\"inv_acc\"]))\r\n",
    "\r\n",
    "    if line_count % resolution==0:\r\n",
    "\r\n",
    "        simultan_clean.append(float(row[\"clean_acc\"]))        \r\n",
    "        simultan_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "        simultan_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_not_simultan_trained:\r\n",
    "    if line_count % resolution==0:\r\n",
    "        not_simultan_clean.append(float(row[\"clean_acc\"]))\r\n",
    "        not_simultan_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "        not_simultan_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_inv_ptb_trained:\r\n",
    "    if line_count % resolution==0:\r\n",
    "        inv_ptb_clean.append(float(row[\"clean_acc\"]))\r\n",
    "        inv_ptb_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "        inv_ptb_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "line_count = 0\r\n",
    "for row in reader_ptb_inv_trained:\r\n",
    "    if line_count % resolution==0:\r\n",
    "        ptb_inv_clean.append(float(row[\"clean_acc\"]))\r\n",
    "        ptb_inv_ptb.append(float(row[\"ptb_acc\"]))\r\n",
    "        ptb_inv_inv.append(float(row[\"inv_acc\"]))\r\n",
    "    line_count+=1\r\n",
    "\r\n",
    "\r\n",
    "y=[]\r\n",
    "i=500\r\n",
    "j=0\r\n",
    "while j<1500:\r\n",
    "    y.append(j)\r\n",
    "    j+=resolution\r\n",
    "\r\n",
    "print(\"Simultan\")  \r\n",
    "plt.plot( y, simultan_clean, label = \"Clean\")\r\n",
    "plt.plot( y, simultan_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, simultan_inv,label = \"INV\")\r\n",
    "plt.xlabel('Iterationen')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "print(\"Not simultan\")\r\n",
    "plt.plot( y, not_simultan_clean, label = \"Clean\")\r\n",
    "plt.plot( y, not_simultan_ptb,label = \"PTB\")\r\n",
    "plt.plot( y, not_simultan_inv,label = \"INV\")\r\n",
    "plt.xlabel('Iterationen')\r\n",
    "plt.ylabel('Accuracy')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n",
    "# print(\"INV-PTB\")\r\n",
    "# plt.plot( y, inv_ptb_clean, label = \"Clean\")\r\n",
    "# plt.plot( y, inv_ptb_ptb,label = \"PTB\")\r\n",
    "# plt.plot( y, inv_ptb_inv,label = \"INV\")\r\n",
    "# plt.xlabel('Iterationen')\r\n",
    "# plt.ylabel('Accuracy')\r\n",
    "# plt.legend()\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "\r\n",
    "# print(\"PTB-INV\")\r\n",
    "# plt.plot( y, ptb_inv_clean, label = \"Clean\")\r\n",
    "# plt.plot( y, ptb_inv_ptb,label = \"PTB\")\r\n",
    "# plt.plot( y, ptb_inv_inv,label = \"INV\")\r\n",
    "# plt.xlabel('Iterationen')\r\n",
    "# plt.ylabel('Accuracy')\r\n",
    "# plt.legend()\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print()\r\n",
    "best_i=0\r\n",
    "best_ptb=0.0\r\n",
    "for i in range(len(simultan_clean_all)):\r\n",
    "    if simultan_ptb_all[i]>best_ptb:\r\n",
    "        best_i=i\r\n",
    "        best_ptb=simultan_ptb_all[i]\r\n",
    "\r\n",
    "print(\"simultan beste werte: \")\r\n",
    "print(\"inv: {}, ptb: {}, i: {}\".format(simultan_inv_all[best_i],simultan_ptb_all[best_i],best_i))\r\n",
    "\r\n",
    "print()\r\n",
    "best_i=0\r\n",
    "best_ptb=0.0\r\n",
    "diff=1\r\n",
    "for i in range(len(simultan_clean_all)):\r\n",
    "    diff_tmp=simultan_inv_all[i]-simultan_ptb_all[i]\r\n",
    "    if diff_tmp<diff:\r\n",
    "        diff=diff_tmp\r\n",
    "        best_i=i\r\n",
    "    \r\n",
    "\r\n",
    "print(\"Nicht simultan beste werte: \")\r\n",
    "print(\"inv: {}, ptb: {}, i: {}\".format(simultan_inv_all[best_i],simultan_ptb_all[best_i],best_i))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vierter Durchlauf (Optimalen Wert fÃ¼r Anzahl an Invariance-Based Adversarial Examples finden)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# util"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checken ob human labels wohl passen...\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# new_labels=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\r\n",
    "# human_labels=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_human_labels.npy\")\r\n",
    "# inv_examples=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\r\n",
    "\r\n",
    "# fig, axes = plt.subplots(10,10, figsize=(20,20))\r\n",
    "# for i in range(100):\r\n",
    "#     ax = axes[i//10,i%10]\r\n",
    "#     ax.imshow(inv_examples[i], cmap='gray')\r\n",
    "#     # ax.set_title('Label: {}'.format(inv_labels_to_train[i]))\r\n",
    "#     ax.set_title('Human: {}, New: {}'.format(human_labels[i], new_labels[i]))\r\n",
    "# plt.tight_layout()\r\n",
    "# plt.show()\r\n",
    "\r\n",
    "\r\n",
    "for i in range(110):\r\n",
    "    res1,res2=next_batch(100,x_train,y_train)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}