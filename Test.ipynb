{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Variables & Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.8.0\n",
      "Numpy version:  1.22.2\n",
      "Foolbox version:  3.3.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Imports\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import foolbox as fb\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import product\n",
    "from scipy.ndimage.interpolation import rotate, shift\n",
    "\n",
    "\n",
    "\n",
    "#Variables\n",
    "epsilon=0.3\n",
    "batch_size=1024\n",
    "epochs=1000\n",
    "pgd_steps=50\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Foolbox version: \", fb.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "#get MNIST data and prepare\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows = img_cols = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#define variables needed for attacks\n",
    "x_attack_to_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_attack_to_train=x_attack_to_train[:,:,:,np.newaxis]\n",
    "y_attack_to_train=tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "\n",
    "x_attack_to_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "x_attack_to_test=x_attack_to_test[:,:,:,np.newaxis]\n",
    "y_attack_to_test=tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "#for generating invariance-based adversarial examples\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Functions\n",
    "def test_model(model):\n",
    "    \n",
    "    assert epsilon==0.3\n",
    "    inv_advs_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03.npy\")[0:100]\n",
    "    inv_labels_to_test=np.load(\"data/invariance_examples_tramer/linf/automated_eps03_labels.npy\")[0:100]\n",
    "    fmodel=fb.models.tensorflow.TensorFlowModel(model, bounds=(0,1))      \n",
    "    attack = fb.attacks.projected_gradient_descent.LinfProjectedGradientDescentAttack(steps=pgd_steps)\n",
    "\n",
    "    # x_batch,y_batch=next_batch(100,x_test,y_test)\n",
    "    x_batch,y_batch=x_test[0:100],y_test[0:100]\n",
    "    x_batch_to_test = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "    y_batch_to_test=tf.convert_to_tensor(y_batch, dtype=tf.int32)\n",
    "\n",
    "    _,advs_to_test, success=attack(fmodel,x_batch_to_test, y_batch_to_test, epsilons=epsilon)\n",
    "   \n",
    "    \n",
    "    success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\n",
    "    x=tf.keras.backend.get_value(advs_to_test)\n",
    "    ptb_test=x\n",
    "\n",
    "    #get accuracies and losses\n",
    "    acc =model.evaluate(x_test[0:100],to_categorical(y_test[0:100]), verbose=0)\n",
    "    acc_ptb = model.evaluate(ptb_test,to_categorical(y_batch), verbose=0)\n",
    "    acc_inv = model.evaluate(inv_advs_to_test,to_categorical(inv_labels_to_test), verbose=0)\n",
    "\n",
    "\n",
    "    # get invariance adversarial examples success rate\n",
    "    predictions=model.predict(inv_advs_to_test)\n",
    "    disagreeing=0\n",
    "    for i in range(len(predictions)):\n",
    "        if inv_labels_to_test[i] !=np.argmax(predictions[i]):\n",
    "            disagreeing+=1\n",
    "    # plt.imshow(ptb_test[0], cmap='gray')\n",
    "    # plt.show()  \n",
    "   \n",
    "      \n",
    "    return {\n",
    "    \"clean\":{\"loss\": acc[0], \"accuracy\":acc[1]},\n",
    "    \"ptb\":{\"loss\": acc_ptb[0], \"accuracy\":acc_ptb[1]},\n",
    "    \"inv\":{\"loss\": acc_inv[0], \"accuracy\":acc_inv[1]},\n",
    "    \"inv_success_rate\":disagreeing/100}\n",
    "\n",
    "\n",
    "def create_vanilla_model():\n",
    "      print(\"creating vanilla model...\")\n",
    "      \n",
    "      val_images = x_train[:10000]\n",
    "      partial_images = x_train[10000:]\n",
    "      val_labels = y_train[:10000]\n",
    "      partial_labels = y_train[10000:]\n",
    "\n",
    "      model = Sequential()\n",
    "\n",
    "      model.add(Conv2D(32, (5, 5), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Conv2D(64, (5, 5), activation='relu', kernel_initializer='he_uniform'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
    "      model.add(Dense(10, activation='softmax'))\n",
    "     \n",
    "\n",
    "\n",
    "      earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 1, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "      model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "      print(\"training vanilla model...\")\n",
    "      history=model.fit(partial_images,to_categorical(partial_labels),\n",
    "                  validation_data =(val_images, to_categorical(val_labels)),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,\n",
    "                  verbose=2,\n",
    "                  callbacks =[earlystopping]\n",
    "                  )\n",
    "      print(np.shape(x_test))\n",
    "      acc = model.evaluate(x_test[0:100],to_categorical(y_test[0:100]))\n",
    "      print('BEFORE RETRAIN: Accuracy on clean testing data', acc[1])\n",
    "\n",
    "      return model\n",
    "\n",
    "def create_vanilla_model_tramer(filters=64, s1=5, s2=5, s3=3,\n",
    "               d1=0, d2=0, fc=256,\n",
    "               lr=1e-3, decay=1e-3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size=(s1, s1),\n",
    "                     activation='relu',\n",
    "                     input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters*2, (s2, s2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters*2, (s3, s3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(d1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(fc, activation='relu'))\n",
    "    model.add(Dropout(d2))\n",
    "    model.add(Dense(10))\n",
    "    \n",
    "   \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    final = Sequential()\n",
    "    final.add(model)\n",
    "    final.add(Activation('softmax'))\n",
    "    final.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    final.fit(x_train, to_categorical(y_train, 10),\n",
    "              batch_size=256,\n",
    "              epochs=20,\n",
    "              shuffle=True,\n",
    "              verbose=2,\n",
    "    )\n",
    "    return final    \n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data\n",
    "# Get random batch of data\n",
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "def linf_attack(x, nn_adv, eps=epsilon):\n",
    "    x_adv = x.copy().astype(np.float32)\n",
    "    nn_adv = nn_adv.astype(np.float32)\n",
    "    \n",
    "    # if possible, change the pixels to the target value\n",
    "    idx = np.where((np.abs(nn_adv - x) <= eps*255.) & (x > 0))\n",
    "    x_adv[idx] = nn_adv[idx]\n",
    "    \n",
    "    # otherwise, go as close as possible\n",
    "    idx = np.where(np.abs(nn_adv - x) > eps*255.)\n",
    "    sign = np.sign(nn_adv - x)\n",
    "    x_adv[idx] += sign[idx] * eps * 255.\n",
    "    \n",
    "    x_adv = np.clip(x_adv, x.astype(np.float32) - eps*255, x.astype(np.float32) + eps*255)\n",
    "    x_adv = np.clip(x_adv, 0, 255.)\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "# tries all rotation-translations of the input and returns the closest neighbor from each class\n",
    "def get_best_neighbors(x, y, all_NNs, grid):\n",
    "    xs = [shift(rotate(x, r, reshape=False), (tx, ty)).reshape(784) for (tx, ty, r) in grid]\n",
    "    xs = np.asarray(xs.copy())\n",
    "    \n",
    "    nns = []\n",
    "    y_nns = []\n",
    "    grids_nn = []\n",
    "    \n",
    "    # find a nearest neighbor in each class\n",
    "    for i in range(10):\n",
    "        if i != y:\n",
    "            X = X_train[Y_train == i]\n",
    "            Y = Y_train[Y_train == i]\n",
    "            distances, indices = all_NNs[i].kneighbors(xs, n_neighbors=1)\n",
    "\n",
    "            best = np.argmin(np.reshape(distances, -1))\n",
    "            best_idx = np.reshape(indices, -1)[best]\n",
    "            nns.append(X[best_idx])\n",
    "            y_nns.append(Y[best_idx])\n",
    "            \n",
    "            # store the inverse rotation+translation to be applied to the target\n",
    "            grids_nn.append(-np.asarray(grid[best]))\n",
    "    \n",
    "    return nns, y_nns, grids_nn\n",
    "\n",
    "\n",
    "# https://github.com/ftramer/Excessive-Invariance\n",
    "def generate_inv_adv_examples(epsilon, count):\n",
    "    import numpy as np\n",
    "    assert epsilon==0.3 or epsilon==0.4\n",
    "    \n",
    "    idxs=np.arange(0,300,1,dtype=int)\n",
    "\n",
    "    #  Load the MNIST data. 300 randomly chosen test point\n",
    "    assert len(idxs) == count\n",
    "    test_xs = X_test[idxs]\n",
    "    test_ys = Y_test[idxs]\n",
    "\n",
    "    # build a nearest neighbors classifier per class\n",
    "    N = 1\n",
    "    all_NNs = []\n",
    "\n",
    "    for i in range(10):\n",
    "        #Reshape to 1D (28*28=784)\n",
    "        X = X_train[Y_train == i].reshape(-1, 784)\n",
    "        nn = NearestNeighbors(n_neighbors=N)\n",
    "    \n",
    "        nn.fit(X)\n",
    "        all_NNs.append(nn)\n",
    "    # print(all_NNs)\n",
    "\n",
    "\n",
    "\n",
    "    # Rotation-translation parameters\n",
    "    limits = [3, 3, 30]\n",
    "    granularity = [5, 5, 31]\n",
    "    grid = list(product(*list(np.linspace(-l, l, num=g) for l, g in zip(limits, granularity))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_nns = []\n",
    "    all_y_nns = []\n",
    "    all_grids_nns = []\n",
    "\n",
    "    # find nearest neighbors for some test inputs (this takes a little while)\n",
    "    for i in range(len(idxs)):\n",
    "        if i % 10 == 0:\n",
    "            print(\"{}/{} done\".format(i, len(idxs)))\n",
    "        x = test_xs[i]\n",
    "        y = test_ys[i]\n",
    "\n",
    "        # find the nearest neighbors for each class, with the corresponding rotation and translation\n",
    "        nns, y_nns, grids_nns = get_best_neighbors(x, y, all_NNs, grid)\n",
    "        nn_advs = [shift(rotate(nn, r, reshape=False), (tx, ty)) for (nn, (tx, ty, r)) in zip(nns, grids_nns)]\n",
    "        all_nns.append(nn_advs)\n",
    "        all_y_nns.append(y_nns)\n",
    "        all_grids_nns.append(np.asarray(grids_nns))\n",
    "\n",
    "\n",
    "\n",
    "    # save everything!\n",
    "    np.save(\"data/invariance_examples_generation/X_test_{}.npy\".format(count), test_xs)\n",
    "    np.save(\"data/invariance_examples_generation/all_nns.npy\", np.asarray(all_nns))\n",
    "    np.save(\"data/invariance_examples_generation/all_y_nns.npy\", np.asarray(all_y_nns))\n",
    "    np.save(\"data/invariance_examples_generation/all_grids_nns.npy\", np.asarray(all_grids_nns))\n",
    "\n",
    "\n",
    "\n",
    "    # (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    all_nns=np.load(\"data/invariance_examples_generation/all_nns.npy\")\n",
    "    all_y_nns=np.load(\"data/invariance_examples_generation/all_y_nns.npy\")\n",
    "    all_grids_nns=np.load(\"data/invariance_examples_generation/all_grids_nns.npy\")\n",
    "    test_xs=np.load(\"data/invariance_examples_generation/X_test_{}.npy\".format(count))\n",
    "  \n",
    "    test_ys = y_test[idxs]\n",
    "\n",
    "    # manually chosen target classes for each source class\n",
    "    targets = {\n",
    "        0: [4, 6, 8, 9],\n",
    "        1: [4, 6, 7, 9],\n",
    "        2: [8],\n",
    "        3: [8],\n",
    "        4: [8, 9],\n",
    "        5: [3, 8],\n",
    "        6: [0],\n",
    "        7: [2, 3],\n",
    "        8: [3],\n",
    "        9: [3, 4, 5]\n",
    "    }\n",
    "\n",
    "    best_y_advs = []\n",
    "    best_targets = []\n",
    "    best_advs = []\n",
    "\n",
    "    for i in range(len(all_nns)):\n",
    "        x = test_xs[i]\n",
    "        y = test_ys[i]\n",
    "    \n",
    "        best_x_adv = None\n",
    "        best_nn_adv = None\n",
    "        amount_removed = []\n",
    "        amount_added = []\n",
    "        rot = []\n",
    "        best_y = None\n",
    "        min_removed = np.inf\n",
    "        for j in range(len(all_nns[i])):\n",
    "            nn_adv = all_nns[i][j]\n",
    "            y_nn = all_y_nns[i][j]\n",
    "            # print(\"NN ADV: {}\".format(np.shape(nn_adv)))\n",
    "            # print(\"X: {}\".format(np.shape(x)))\n",
    "            x_adv = linf_attack(x, nn_adv, eps=epsilon)\n",
    "        \n",
    "            \n",
    "            # retain the target that required the least amount of pixels to be \"removed\"\n",
    "            curr_rot = np.abs(all_grids_nns[i][j][-1])\n",
    "            curr_removed = np.sum(np.abs(np.maximum(x/255. - x_adv/255., 0)))\n",
    "            \n",
    "            if y_nn in targets[y] and curr_removed < min_removed:\n",
    "                min_removed = curr_removed\n",
    "                best_y = y_nn\n",
    "                best_x_adv = x_adv\n",
    "                best_nn_adv = (nn_adv, y_nn)\n",
    "                    \n",
    "        best_targets.append(best_nn_adv)\n",
    "        best_advs.append(best_x_adv)\n",
    "        best_y_advs.append(best_y)\n",
    "        \n",
    "\n",
    "    \n",
    "    if epsilon==0.3:\n",
    "        np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples\", best_advs)\n",
    "        np.save(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels\", best_y_advs)\n",
    "    else:\n",
    "        np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples\", best_advs)\n",
    "        np.save(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels\", best_y_advs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create/train vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vanilla_model().save(\"models/vanilla_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack Vanilla Model and Retrain with Perturbation-Based Adversarial Examples iteratively\n",
    "Result is ptb_trained_model\n",
    "\n",
    "Takes a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Model\n",
    "model=load_model(\"models/vanilla_model\")\n",
    "\n",
    "ptb_acc_to_achieve=0.88\n",
    "ptb_acc=0\n",
    "i=0\n",
    "y_axis=[]\n",
    "x_axis_ptb=[]\n",
    "x_axis_clean=[]\n",
    "\n",
    "attack = fb.attacks.projected_gradient_descent.LinfProjectedGradientDescentAttack(steps=pgd_steps)\n",
    "# print(\"Attacking and retraining \",iterations,\" times (Can take a couple of minutes):\")\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 1, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "#While ACCURACY\n",
    "while ptb_acc<=ptb_acc_to_achieve:\n",
    "    res=test_model(model)\n",
    "    ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "    clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "\n",
    "    i+=1\n",
    "    y_axis.append(i)\n",
    "    x_axis_ptb.append(ptb_acc)\n",
    "    x_axis_clean.append(clean_acc)\n",
    "    fmodel=fb.models.tensorflow.TensorFlowModel(model, bounds=(0,1))   \n",
    "    x_batch,y_batch=next_batch(50,x_train,y_train)\n",
    "    x_batch_to_train = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "    y_batch_to_train=tf.convert_to_tensor(y_batch, dtype=tf.int32)\n",
    "\n",
    "    #attack model    \n",
    "    _,advs, success=attack(fmodel, x_batch_to_train, y_batch_to_train, epsilons=epsilon) \n",
    "    success_rate=tf.keras.backend.get_value(success).mean(axis=-1).round(2)\n",
    "    \n",
    "    #Retrain model with generated perturbation-based adversarial examples\n",
    "    #80% Training 20% Validation\n",
    "    x=tf.keras.backend.get_value(advs)\n",
    "    # print(\"Shape of x_training before reshape: {}\".format(np.shape(x)))\n",
    "    # print(\"Shape of x_training after reshape: {}\".format(np.shape(x)))\n",
    "    x_training=x[0:int(len(x)*0.8)]\n",
    "    x_validation=x[int(len(x)*0.8):int(len(x))]\n",
    "    y_training=y_batch[0:int(len(x)*0.8)]\n",
    "    y_validation=y_batch[int(len(x)*0.8):int(len(x))]\n",
    "    \n",
    "    model.fit(x_training,to_categorical(y_training,num_classes=10),\n",
    "        validation_data =(x_validation,to_categorical(y_validation, num_classes=10)),\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        callbacks =[earlystopping]\n",
    "    )\n",
    "   \n",
    "\n",
    "    print(\"i: {} ptb acc: {}\".format(i,ptb_acc))\n",
    "model.save(\"models/ptb_trained_model_{}_ptb_accuracy\".format(ptb_acc))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot( y_axis, x_axis_clean, label = \"Clean\")\n",
    "plt.plot( y_axis, x_axis_ptb,label = \"PTB\")\n",
    "plt.xlabel('Iterationen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PTB Adversarial Training graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(array):\n",
    "    filtered=[]\n",
    "    for i in range(len(array)):\n",
    "        if i%10==0:\n",
    "            filtered.append(array[i])\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "y=np.load(\"data/ptb_training/iteration_count_arr.npy\")\n",
    "clean_arr=np.load(\"data/ptb_training/clean_accuracy_arr.npy\")\n",
    "ptb_arr=np.load(\"data/ptb_training/ptb_accuracy_arr.npy\")\n",
    "plt.plot( y, clean_arr, label = \"Clean\")\n",
    "plt.plot( y, ptb_arr,label = \"PTB\")\n",
    "plt.xlabel('Iterationen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "new_arr_x_ptb=filter_array(ptb_arr)\n",
    "new_arr_x_clean=filter_array(clean_arr)\n",
    "new_arr_y=filter_array(y)\n",
    "\n",
    "\n",
    "plt.plot( new_arr_y, new_arr_x_clean, label = \"Clean\")\n",
    "plt.plot( new_arr_y, new_arr_x_ptb,label = \"PTB\")\n",
    "plt.xlabel('Iterationen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Max accuracy against PTB: {}\".format(np.max(ptb_arr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate INV-Based ADV-Examples \n",
    "Code is from https://github.com/ftramer/Excessive-Invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/300 done\n",
      "10/300 done\n",
      "20/300 done\n",
      "30/300 done\n",
      "40/300 done\n",
      "50/300 done\n",
      "60/300 done\n",
      "70/300 done\n",
      "80/300 done\n",
      "90/300 done\n",
      "100/300 done\n",
      "110/300 done\n",
      "120/300 done\n",
      "130/300 done\n",
      "140/300 done\n",
      "150/300 done\n",
      "160/300 done\n",
      "170/300 done\n",
      "180/300 done\n",
      "190/300 done\n",
      "200/300 done\n",
      "210/300 done\n",
      "220/300 done\n",
      "230/300 done\n",
      "240/300 done\n",
      "250/300 done\n",
      "260/300 done\n",
      "270/300 done\n",
      "280/300 done\n",
      "290/300 done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_inv_adv_examples(0.4,300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot INV-Based ADV-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON=0.3\n"
     ]
    }
   ],
   "source": [
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.3/invariance-based_adversarial_examples_new_labels.npy\")\n",
    "\n",
    "print(\"EPSILON=0.3\")\n",
    "fig, axes = plt.subplots(30,10, figsize=(1.5*10,2*30))\n",
    "for i in range(300):\n",
    "    ax = axes[i//10,i%10]\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\n",
    "    # ax.set_title('Label: {}'.format(inv_labels_to_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples.npy\")\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples/epsilon_0.4/invariance-based_adversarial_examples_new_labels.npy\")\n",
    "\n",
    "print(\"EPSILON=0.4\")\n",
    "fig, axes = plt.subplots(30,10, figsize=(1.5*10,2*30))\n",
    "for i in range(300):\n",
    "    ax = axes[i//10,i%10]\n",
    "    ax.imshow(inv_advs_to_train[i], cmap='gray')\n",
    "    # ax.set_title('Label: {}'.format(inv_labels_to_train[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain Models with Invariance-Based Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/inv_trained_model\\assets\n",
      "INFO:tensorflow:Assets written to: models/ptb_inv_trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Load data and model\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy\")\n",
    "\n",
    "\n",
    "# inv_advs_to_train=np.load(\"data/invariance_examples/invariance-based_adversarial_examples.npy\")\n",
    "# inv_labels_to_train=np.load(\"data/invariance_examples/invariance-based_adversarial_examples_labels.npy\")\n",
    "\n",
    "inv_advs_to_train=np.load(\"data/invariance_examples_tramer/linf/automated_eps03.npy\")[0:10]\n",
    "inv_labels_to_train=np.load(\"data/invariance_examples_tramer/linf/automated_eps03_labels.npy\")[0:10]\n",
    "\n",
    "\n",
    "#retrain with inv-based adv examples\n",
    "vanilla_model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0,)\n",
    "\n",
    "vanilla_model.save(\"models/inv_trained_model\")\n",
    "\n",
    "ptb_trained_model.fit(inv_advs_to_train,to_categorical(inv_labels_to_train,num_classes=10),\n",
    "    epochs=10,\n",
    "    verbose=0,)\n",
    "\n",
    "ptb_trained_model.save(\"models/ptb_inv_trained_model\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002774CE9C8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "----------Vanilla Model----------\n",
      "Clean Accuracy: 0.9901999831199646\n",
      "PTB Accuracy: 0.0\n",
      "INV Accuracy: 0.800000011920929\n",
      "INV attack Success rate: 0.18\n",
      "\n",
      "----------PTB-Trained Model----------\n",
      "Clean Accuracy: 0.961899995803833\n",
      "PTB Accuracy: 0.8899999856948853\n",
      "INV Accuracy: 0.5888888835906982\n",
      "INV attack Success rate: 0.37\n",
      "\n",
      "----------PTB-INV-Trained Model----------\n",
      "Clean Accuracy: 0.9646000266075134\n",
      "PTB Accuracy: 0.8199999928474426\n",
      "INV Accuracy: 0.6666666865348816\n",
      "INV attack Success rate: 0.3\n",
      "\n",
      "----------INV-Trained Model----------\n",
      "Clean Accuracy: 0.953000009059906\n",
      "PTB Accuracy: 0.0\n",
      "INV Accuracy: 0.7555555701255798\n",
      "INV attack Success rate: 0.22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptb_trained_model=load_model(\"models/ptb_trained_model_0.889_ptb_accuracy\")\n",
    "vanilla_model=load_model(\"models/vanilla_model\")\n",
    "ptb_inv_trained_model=load_model(\"models/ptb_inv_trained_model\")\n",
    "inv_trained_model=load_model(\"models/inv_trained_model\")\n",
    "\n",
    "\n",
    "res=test_model(vanilla_model)\n",
    "vanilla_model_clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "vanilla_model_ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "vanilla_model_inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "vanilla_model_inv_success_rate=res.get(\"inv_success_rate\")\n",
    "\n",
    "print(\"----------Vanilla Model----------\")\n",
    "print(\"Clean Accuracy: {}\".format(vanilla_model_clean_acc))\n",
    "print(\"PTB Accuracy: {}\".format(vanilla_model_ptb_acc))\n",
    "print(\"INV Accuracy: {}\".format(vanilla_model_inv_acc))\n",
    "print(\"INV attack Success rate: {}\".format(vanilla_model_inv_success_rate))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res=test_model(ptb_trained_model)\n",
    "ptb_model_clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "ptb_model_ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "ptb_model_inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "ptb_model_inv_success_rate=res.get(\"inv_success_rate\")\n",
    "\n",
    "print(\"----------PTB-Trained Model----------\")\n",
    "print(\"Clean Accuracy: {}\".format(ptb_model_clean_acc))\n",
    "print(\"PTB Accuracy: {}\".format(ptb_model_ptb_acc))\n",
    "print(\"INV Accuracy: {}\".format(ptb_model_inv_acc))\n",
    "print(\"INV attack Success rate: {}\".format(ptb_model_inv_success_rate))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res=test_model(ptb_inv_trained_model)\n",
    "ptb_inv_model_clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "ptb_inv_model_ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "ptb_inv_model_inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "ptb_inv_model_inv_success_rate=res.get(\"inv_success_rate\")\n",
    "\n",
    "print(\"----------PTB-INV-Trained Model----------\")\n",
    "print(\"Clean Accuracy: {}\".format(ptb_inv_model_clean_acc))\n",
    "print(\"PTB Accuracy: {}\".format(ptb_inv_model_ptb_acc))\n",
    "print(\"INV Accuracy: {}\".format(ptb_inv_model_inv_acc))\n",
    "print(\"INV attack Success rate: {}\".format(ptb_inv_model_inv_success_rate))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res=test_model(inv_trained_model)\n",
    "inv_model_clean_acc=res.get(\"clean\").get(\"accuracy\")\n",
    "inv_model_ptb_acc=res.get(\"ptb\").get(\"accuracy\")\n",
    "inv_model_inv_acc=res.get(\"inv\").get(\"accuracy\")\n",
    "inv_model_inv_success_rate=res.get(\"inv_success_rate\")\n",
    "\n",
    "print(\"----------INV-Trained Model----------\")\n",
    "print(\"Clean Accuracy: {}\".format(inv_model_clean_acc))\n",
    "print(\"PTB Accuracy: {}\".format(inv_model_ptb_acc))\n",
    "print(\"INV Accuracy: {}\".format(inv_model_inv_acc))\n",
    "print(\"INV attack Success rate: {}\".format(inv_model_inv_success_rate))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
